# PIPELINE DEFINITION
# Name: epos-training
# Description: My ML pipeline.
components:
  comp-setup-train:
    executorLabel: exec-setup-train
deploymentSpec:
  executors:
    exec-setup-train:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - setup_train
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pyyaml' &&\
          \ \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef setup_train():\n    import subprocess\n    import yaml\n    import\
          \ requests\n\n    new_params_yaml ={\n      \"dataset\": \"carObj12\",\n\
          \      \"model_variant\": \"xception_65\",\n      \"atrous_rates\": [12,\
          \ 24, 36],\n      \"encoder_output_stride\": 8,\n      \"decoder_output_stride\"\
          : [4],\n      \"upsample_logits\": False,\n      \"frag_seg_agnostic\":\
          \ False,\n      \"frag_loc_agnostic\": False,\n      \"num_frags\": 64,\n\
          \      \"corr_min_obj_conf\": 0.1,\n      \"corr_min_frag_rel_conf\": 0.5,\n\
          \      \"corr_project_to_model\": False,\n      \"train_tfrecord_names\"\
          : [\"carObj12_train-primesense\"],\n      \"train_max_height_before_crop\"\
          : 480,\n      \"train_crop_size\": \"640, 480\",\n      \"freeze_regex_list\"\
          : [\"xception_65/entry_flow\"],\n      \"initialize_last_layer\": True,\n\
          \      \"fine_tune_batch_norm\": False,\n      \"train_steps\": 15480,\n\
          \      \"train_batch_size\": 1,\n      \"base_learning_rate\": 0.0000001,\n\
          \      \"learning_power\": 0.9,\n      \"obj_cls_loss_weight\": 1.0,\n \
          \     \"frag_cls_loss_weight\": 1.0,\n      \"frag_loc_loss_weight\": 100.0,\n\
          \      \"train_knn_frags\": 1,\n      \"data_augmentations\": {\n      \
          \  \"random_adjust_brightness\": {\n          \"min_delta\": -0.2,\n   \
          \       \"max_delta\": 0.4\n        },\n        \"random_adjust_contrast\"\
          : {\n          \"min_delta\": 0.6,\n          \"max_delta\": 1.4\n     \
          \   },\n        \"random_adjust_saturation\": {\n          \"min_delta\"\
          : 0.6,\n          \"max_delta\": 1.4\n        },\n        \"random_adjust_hue\"\
          : {\n          \"max_delta\": 1.0\n        },\n        \"random_blur\":\
          \ {\n          \"max_sigma\": 1.5\n        },\n        \"random_gaussian_noise\"\
          : {\n          \"max_sigma\": 0.1\n        }\n      },\n      \"eval_tfrecord_names\"\
          : [\"tless_test_targets-bop19\"],\n      \"eval_max_height_before_crop\"\
          : 480,\n      \"eval_crop_size\": \"640, 480\",\n      \"infer_tfrecord_names\"\
          : [\"carObj12_test\"],\n      \"infer_max_height_before_crop\": 480,\n \
          \     \"infer_crop_size\": \"640, 480\"\n    }\n    # Save the dictionary\
          \ to a YAML file\n    with open('/app/store/tf_models/obj12/params.yml',\
          \ 'w') as file:\n        yaml.dump(new_params_yaml, file, default_flow_style=False)\n\
          \    # Define source and destination paths\n    #url = \"http://10.42.0.99:4422/download/epos\"\
          \n    #output_file = \"datasets/carObj12/train_primesense/training_epos_Objs12.zip\"\
          \n    #subprocess.run(\"mkdir -p datasets/carObj12/train_primesense/\",shell=True)\n\
          \    # Send a GET request to the URL\n    #response = requests.get(url)\n\
          \n    # Check if the request was successful\n    #if response.status_code\
          \ == 200:\n        # Write the content of the response to a file\n    #\
          \    with open(output_file, \"wb\") as f:\n    #        f.write(response.content)\n\
          \    #    print(f\"Downloaded {output_file} successfully.\")\n    #else:\n\
          \    #    print(f\"Failed to download file. Status code: {response.status_code}\"\
          )\n    subprocess.run(\"cp -r /datasets/epos/training_set /app/datasets/carObj12/\"\
          ,shell=True)\n    subprocess.run(\"mv /app/datasets/carObj12/training_set\
          \ /app/datasets/carObj12/train_primesense\",shell=True)\n\n    # Run the\
          \ command in a new shell\n    subprocess.run(\"conda run -n epos python\
          \ epos/scripts/create_example_list.py --dataset=carObj12 --split=train --split_type=primesense\"\
          , shell=True)\n    subprocess.run(\n        \"conda run -n epos python epos/scripts/create_tfrecord.py\
          \ --dataset=carObj12 --split=train --split_type=primesense --examples_filename=carObj12_train-primesense_examples.txt\
          \ --add_gt=True --shuffle=True --rgb_format=png\",\n        shell=True)\n\
          \    subprocess.run(\n        \"conda run -n epos python epos/scripts/train.py\
          \ --model=obj12\",\n        shell=True)\n\n"
        image: gkorod/topo:v1.1
        resources:
          accelerator:
            count: '1'
            type: nvidia.com/gpu
pipelineInfo:
  description: My ML pipeline.
  name: epos-training
root:
  dag:
    tasks:
      setup-train:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-setup-train
        taskInfo:
          name: setup-train
schemaVersion: 2.1.0
sdkVersion: kfp-2.7.0
---
platforms:
  kubernetes:
    deploymentSpec:
      executors:
        exec-setup-train:
          pvcMount:
          - constant: trained-models
            mountPath: /trained_models
          - constant: datasets
            mountPath: /datasets
